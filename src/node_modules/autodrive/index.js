const Autobase = require('autobase')
const Hyperdrive = require('hyperdrive')
const b4a = require('b4a')
const { EventEmitter } = require('events')

function create_autodrive (options) {
  const { store, bootstrap, opts = {} } = options
  const emitter = new EventEmitter()
  const state = {
    store,
    drive: null,
    bootstrap,
    readers: new Set(),
    writers: new Set(),
    opts,
    base: null
  }

  // Autobase handlers
  function handle_autobase_open (store) {
    const drive_store = store.base.store.namespace('autodrive-' + store.base.version)
    const drive = new Hyperdrive(drive_store)
    return { drive }
  }

  async function handle_autobase_apply (nodes, view, base) {
    await view.drive.ready()
    const batch = view.drive.batch()
    for (const node of nodes) {
      const { type, data = {} } = node.value || {}
      if (!type) continue

      if (type === 'put') {
        const buffer = b4a.from(data.content, 'base64')
        await batch.put(data.path, buffer)
        emitter.emit('content-added', { path: data.path, content: buffer })
      } else if (type === 'del') {
        await batch.del(data.path)
      } else if (type === 'add_writer') {
        const key = b4a.from(data.key, 'hex')
        await base.addWriter(key, { indexer: data.is_indexer }) // Grant write access
        state.writers.add(data.key)
        emitter.emit('writer-added', { key: data.key, is_indexer: data.is_indexer })
      } else if (type === 'add_reader') {
        state.readers.add(data.key)
        emitter.emit('reader-added', { key: data.key })
      } else if (type === 'remove_writer') {
        const key = b4a.from(data.key, 'hex')
        await base.removeWriter(key)
        state.writers.delete(data.key)
        emitter.emit('writer-removed', { key: data.key })
      } else if (type === 'remove_reader') {
        state.readers.delete(data.key)
        emitter.emit('reader-removed', { key: data.key })
      }
    }
    await batch.flush()
  }

  async function handle_autobase_close (view) {
    await view.drive.close()
  }

  state.base = new Autobase(store, bootstrap, {
    inputs: [store.get({ name: 'writer' })],
    valueEncoding: 'json',
    open: handle_autobase_open,
    apply: handle_autobase_apply,
    close: handle_autobase_close,
    ackInterval: opts.ack_interval || 5000
  })

  const api = {
    on: (event, listener) => emitter.on(event, listener),
    off: (event, listener) => emitter.off(event, listener),
    emit: (event, ...args) => emitter.emit(event, ...args),
    get base () { return state.base },
    async ready () {
      await state.base.ready()
      state.drive = state.base.view.drive
    },
    async init () {
      if (!state.bootstrap) return
    },
    async close () {
      await state.base.close()
    },
    async put (path, content) {
      await api.ready()
      await state.base.append({ type: 'put', data: { path, content: b4a.toString(content, 'base64') } })
    },
    async del (path) {
      await api.ready()
      await state.base.append({ type: 'del', data: { path } })
      await state.base.update()
    },
    async get (path, opts) {
      await api.ready()
      return state.drive.get(path, opts)
    },

    async list (folder = '/', opts = {}) {
      await api.ready()
      // List only immediate children (files and directories)
      const entries = []
      async function collect_entry_keys () {
        for await (const entry of await state.drive.list(folder, { ...opts, recursive: false })) {
          entries.push(entry.key)
        }
      }
      await collect_entry_keys()
      return entries
    },
    replicate (isInitiator, options) {
      return state.base.replicate(isInitiator, options)
    },
    async download (folder = '/', opts) {
      if (typeof folder === 'object') return api.download(undefined, folder)
      const dls = []
      const entry = (!folder || folder.endsWith('/')) ? null : await state.drive.entry(folder)
      if (entry) {
        const b = entry.value.blob
        if (!b) return
        const blobs = await state.drive.getBlobs()
        await blobs.core.download({ start: b.blockOffset, length: b.blockLength }).downloaded() // Download single file
        return
      }
      async function iterate_drive_list () {
        for await (const _ of state.drive.list(folder, opts)) {}
      }

      async function collect_download_promises () {
        for await (const entry of state.drive.list(folder, opts)) {
          const b = entry.value.blob
          if (!b) continue
          const blobs = await state.drive.getBlobs()
          dls.push(blobs.core.download({ start: b.block_offset, length: b.block_length }))
        }
      }

      await iterate_drive_list()
      await collect_download_promises()
      const proms = []
      function collect_download_promise (r) {
        proms.push(r.downloaded())
      }
      dls.forEach(collect_download_promise)
      await Promise.allSettled(proms)
    },
    async add_writer (key, opts = {}) {
      const key_str = typeof key === 'string' ? key : key.toString('hex')
      const is_indexer = opts.is_indexer === undefined ? true : !!opts.is_indexer
      await state.base.append({ type: 'add_writer', data: { key: key_str, is_indexer } })
      await state.base.update()
    },
    async add_reader (key) {
      const key_str = typeof key === 'string' ? key : key.toString('hex')
      await state.base.append({ type: 'add_reader', data: { key: key_str } })
      await state.base.update()
    },
    async remove_reader (key) {
      const key_str = typeof key === 'string' ? key : key.toString('hex')
      await state.base.append({ type: 'remove_reader', data: { key: key_str } })
      await state.base.update()
    },
    async remove_writer (key) {
      const key_str = typeof key === 'string' ? key : key.toString('hex')
      await state.base.append({ type: 'remove_writer', data: { key: key_str } })
      await state.base.update()
    },
    get_readers () { return Array.from(state.readers) },
    get_writers () { return Array.from(state.writers) },
    is_reader (key) {
      const key_str = typeof key === 'string' ? key : key.toString('hex')
      return state.readers.has(key_str)
    },
    is_writer (key) {
      const key_str = typeof key === 'string' ? key : key.toString('hex')
      // Check local state, autobase writers, or if it's the base key
      return !!state.writers.has(key_str) || (state.base.writers && state.base.writers.some(w => w.key.toString('hex') === key_str)) || key_str === state.base.key.toString('hex')
    },
    async exists (path) {
      try {
        return !!(await state.drive.get(path))
      } catch {
        return false
      }
    },
    replicate (stream_or_initiator, opts = {}) {
      if (typeof stream_or_initiator === 'boolean') return state.store.replicate(stream_or_initiator, opts)
      const stream = stream_or_initiator
      return state.store.replicate(stream, opts)
    }
  }
  return api
}

// Static function to get local core (copied from Autobase to avoid full import) // i just copied it from easybase to send writer key before pairing.
function getLocalCore (options) {
  const { store, handlers, encryptionKey } = options
  const messages = require('autobase/lib/messages')
  const opts = { ...handlers, compat: false, active: false, exclusive: true, valueEncoding: messages.OplogMessage, encryptionKey }
  return opts.keyPair ? store.get(opts) : store.get({ ...opts, name: 'local' })
}

module.exports = { create_autodrive, getLocalCore }
