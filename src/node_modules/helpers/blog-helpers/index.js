// Simple P2P blog helper
const Autobase = require('autobase')
const b4a = require('b4a')
const { create_autodrive } = require('../../autodrive')

// emitter
function make_emitter (state = {}) {
  return { on, off, emit }
  function on (type, callback) { (state[type] = state[type] || []).push(callback) }
  function off (type, callback) { (state[type] = state[type] || [])[state[type].indexOf(callback)] = undefined }
  function emit (type, data) {
    function handle_callback (f) {
      return f && f(data)
    }
    return (state[type] = state[type] || []).map(handle_callback)
  }
}

// Global state
let store, blog_autobase, drive, profile_drive, events_drive, metadata_store, drive_store, profile_store, events_store
const discovered_blogs = new Map() // Blogs available in explore tab
const autobase_cache = new Map()
const drive_cache = new Map()
const profile_cache = new Map()
const emitter = make_emitter()

// Validation functions
function validate_blog_init (entry) {
  const { type, data = {} } = entry || {}
  return type === 'blog-init' &&
         typeof data.username === 'string' &&
         typeof data.title === 'string' &&
         typeof data.drive_key === 'string'
}

function validate_blog_post (entry) {
  const { type, data = {} } = entry || {}
  return type === 'blog-post' &&
         typeof data.filepath === 'string' &&
         typeof data.created === 'number'
}

// Local storage helpers
const get_subscribed_peers = () => {
  try { return JSON.parse(localStorage.getItem('subscribed_peers') || '[]') } catch { return [] }
}
const add_subscribed_peer = key => {
  const peers = get_subscribed_peers()
  if (!peers.includes(key)) {
    peers.push(key)
    localStorage.setItem('subscribed_peers', JSON.stringify(peers))
  }
}
const remove_subscribed_peer = key => {
  function filter_peer (k) {
    return k !== key
  }
  localStorage.setItem('subscribed_peers', JSON.stringify(get_subscribed_peers().filter(filter_peer)))
}

// Create autobase (new or paired)
function create_blog_autobase (metadata_store, key = null) {
  return new Autobase(metadata_store, key, {
    valueEncoding: 'json',
    open: (store) => store.get({ name: 'blog-view' }),
    apply: async (batch, view, base) => {
      for (const entry of batch) {
        const { type, data = {} } = entry.value || {}
        if (type === 'addWriter') {
          const writer_key = b4a.from(data.key, 'hex')
          await base.addWriter(writer_key, { isIndexer: true })
        } else if (type) {
          await view.append(JSON.stringify(entry.value))
        }
      }
    }
  })
}

// Setup peer autobase
async function setup_peer_autobase (key, key_buffer) {
  const peer_metadata_store = store.namespace(`peer-metadata-${key}`)
  const peer_autobase = create_blog_autobase(peer_metadata_store, key_buffer)
  await peer_autobase.ready()

  // Wait for init blog to replicate if needed (peer might not have data yet)
  if (peer_autobase.view.length === 0) {
    function handle_update_resolve (resolve) {
      return () => resolve()
    }
    await new Promise(resolve => peer_autobase.once('update', handle_update_resolve(resolve)))
  }

  async function handle_peer_autobase_update () {
    if (peer_autobase.view.length > 0) {
      try {
        // Always check entry[0] for blog-init metadata
        const init_raw_data = await peer_autobase.view.get(0)
        const init_entry = JSON.parse(b4a.toString(init_raw_data))

        if (validate_blog_init(init_entry) && !get_subscribed_peers().includes(key)) {
          const { data } = init_entry
          discovered_blogs.set(key, { ...data, key }) // Add to explore tab
          autobase_cache.set(key, peer_autobase)
          // Note: peer profile drive is created in subscribe(), not here
        }

        // Always emit update when peer data changes (for both discovered and subscribed)
        emitter.emit('update')

        // Check if latest entry is a new post (for notifications)
        if (peer_autobase.view.length > 1) {
          const latest_index = peer_autobase.view.length - 1
          const latest_raw_data = await peer_autobase.view.get(latest_index)
          const latest_entry = JSON.parse(b4a.toString(latest_raw_data))

          if (validate_blog_post(latest_entry)) {
            store.emit('feed', peer_autobase) // Notify about new posts
          }
        }
      } catch (err) {
        console.error('[peer_autobase_update] Error:', err)
      }
    }
  }

  peer_autobase.on('update', handle_peer_autobase_update)

  return peer_autobase
}

// Restore subscribed peers on startup
async function restore_subscribed_peers () {
  for (const key of get_subscribed_peers()) {
    try {
      const peer_autobase = await setup_peer_autobase(key, b4a.from(key, 'hex'))
      if (peer_autobase.view.length > 0) {
        autobase_cache.set(key, peer_autobase)
        const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
        const { data } = init_block
        const peer_drive_store = store.namespace(`peer-drive-${data.drive_key}`)
        drive_cache.set(key, create_autodrive({ store: peer_drive_store, bootstrap: b4a.from(data.drive_key, 'hex') }))
        
        // Setup peer profile drive if profile_drive_key exists
        if (data.profile_drive_key) {
          const peer_profile_store = store.namespace(`peer-profile-${data.profile_drive_key}`)
          const peer_profile_drive = create_autodrive({ store: peer_profile_store, bootstrap: b4a.from(data.profile_drive_key, 'hex') })
          await peer_profile_drive.ready()
          profile_cache.set(key, peer_profile_drive)
        }
      }
    } catch (err) {
      console.error('Error restoring peer:', key.slice(0, 16) + '...', err)
    }
  }
}

// Initialize blog - join or create
async function init_blog (options) {
  const {
    store_instance,
    username,
    drive_key = null,
    autobase_key = null,
    profile_drive_key = null
  } = options


  store = store_instance

  // Create namespaced stores (deterministic - same namespace always returns same store)
  metadata_store = store.namespace('blog-metadata')
  drive_store = store.namespace('blog-files')
  profile_store = store.namespace('blog-profile')
  events_store = store.namespace('blog-events')

  // Create autobase and drive based on whether keys are provided
  blog_autobase = create_blog_autobase(metadata_store, autobase_key)
  drive = create_autodrive({ store: drive_store, bootstrap: drive_key })

  // Only create profile drive and events drive if we have a key (either local or shared)
  if (profile_drive_key) {
    profile_drive = create_autodrive({ store: profile_store, bootstrap: profile_drive_key })
    events_drive = create_autodrive({ store: events_store, bootstrap: null })
    await Promise.all([blog_autobase.ready(), drive.ready(), profile_drive.ready(), events_drive.ready()])
  } else if (!autobase_key) {
    // Only create local profile and events for new blogs (not when joining)
    profile_drive = create_autodrive({ store: profile_store, bootstrap: null })
    events_drive = create_autodrive({ store: events_store, bootstrap: null })
    await Promise.all([blog_autobase.ready(), drive.ready(), profile_drive.ready(), events_drive.ready()])
  } else {
    // Joining without profile key yet - don't create profile or events drive
    await Promise.all([blog_autobase.ready(), drive.ready()])
    await blog_autobase.update()
    await drive.download('/')
  }

  if (!autobase_key && blog_autobase.view.length === 0) {
    // Create init blog for new identity (not joining existing blog)
    const init_data = {
      type: 'blog-init',
      data: {
        drive_key: b4a.toString(drive.base.key, 'hex'),
        profile_drive_key: b4a.toString(profile_drive.base.key, 'hex'),
        events_drive_key: b4a.toString(events_drive.base.key, 'hex'),
        title: `${username}'s Blog`,
        username
      }
    }
    await blog_autobase.append(init_data)
    await blog_autobase.update()
    
    // Create default profile
    await create_default_profile(username)
    
    // Log bootstrap device as Device 1
    await log_event('add', {
      metadata_writer: b4a.toString(blog_autobase.local.key, 'hex'),
      drive_writer: b4a.toString(drive.base.local.key, 'hex'),
      profile_writer: b4a.toString(profile_drive.base.local.key, 'hex'),
      events_writer: b4a.toString(events_drive.base.local.key, 'hex')
    })
  }

  // Replication is now handled in web-peer

  setup_event_handlers()
  await restore_subscribed_peers()
  
  // Setup event sync listeners if events drive exists
  if (events_drive) {
    setup_events_sync_listeners()
  }
  
  emitter.emit('update')
}

// Setup event sync listeners (call this whenever events_drive is available)
function setup_events_sync_listeners () {
  // Setup real-time event sync for NEW events
  events_drive.on('content-added', async ({ path, content }) => {
    if (!content) return
    
    const event = JSON.parse(b4a.toString(content))
    if (path.includes('-sub.json')) {
      add_subscribed_peer(event.data.peer_key)
      discovered_blogs.delete(event.data.peer_key)
      console.log('Subscribed to peer:', event.data.peer_key.slice(0, 16))
      emitter.emit('update')
    } else if (path.includes('-unsub.json')) {
      remove_subscribed_peer(event.data.peer_key)
      const peer_autobase = autobase_cache.get(event.data.peer_key)
      if (peer_autobase && peer_autobase.view.length > 0) {
        const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
        if (init_block.data) discovered_blogs.set(event.data.peer_key, { ...init_block.data, key: event.data.peer_key })
      }
      console.log('Unsubscribed from peer:', event.data.peer_key.slice(0, 16))
      emitter.emit('update')
    } else if (path.includes('-add.json')) {
      console.log('Device added:', event.data.metadata_writer.slice(0, 16))
      emitter.emit('update')
    } else if (path.includes('-remove.json')) {
      console.log('Device removed:', event.data.metadata_writer.slice(0, 16))
      emitter.emit('update')
    }
  })
  
  // Sync on autobase updates (for replicated content)
  if (events_drive.base) {
    events_drive.base.on('update', () => {
      sync_events_to_subscriptions()
    })
  }
  
  // Initial sync
  sync_events_to_subscriptions()
}

// Sync events drive to subscribed peers localStorage
async function sync_events_to_subscriptions () {
  if (!events_drive) return
  
  try {
    const events = await get_events()
    const peer_states = new Map() // Track latest state per peer
    
    // Process events in order to find latest state for each peer
    for (const event of events) {
      if ((event.type === 'sub' || event.type === 'unsub') && event.data.peer_key) {
        peer_states.set(event.data.peer_key, event.type)
      }
    }
    
    // Apply final states
    for (const [peer_key, state] of peer_states) {
      if (state === 'sub') {
        add_subscribed_peer(peer_key)
      } else {
        remove_subscribed_peer(peer_key)
      }
    }
  } catch (err) {
    console.error('Error syncing events:', err)
  }
}

// Setup common event handlers
function setup_event_handlers () {
  function handle_emit_update () {
    emitter.emit('update')
  }

  async function handle_autobase_update () {
    emitter.emit('update')
  }

  blog_autobase.on('append', handle_emit_update)
  blog_autobase.on('update', handle_autobase_update)
  store.on('feed', handle_emit_update)

  async function handle_peer_autobase_key ({ key, key_buffer }) {
    if (key === b4a.toString(blog_autobase.key, 'hex')) {
      // This is our own blog key - set up our profile drive if we're joining an existing blog
      if (blog_autobase.view.length > 0) {
        try {
          const init_raw_data = await blog_autobase.view.get(0)
          const init_entry = JSON.parse(b4a.toString(init_raw_data))
          if (validate_blog_init(init_entry) && init_entry.data.profile_drive_key && !profile_drive) {
            // Recreate profile drive with the correct bootstrap key
            const profile_drive_key = init_entry.data.profile_drive_key
            profile_drive = create_autodrive({ store: profile_store, bootstrap: b4a.from(profile_drive_key, 'hex') })
            await profile_drive.ready()
            
            // Setup replication for the profile drive
            if (store.swarm) {
              function handle_own_profile_replication (conn) {
                profile_store.replicate(conn)
              }
              store.swarm.connections.forEach(handle_own_profile_replication)
            }
          }
        } catch (err) {
          console.warn('Error setting up own profile drive:', err)
        }
      }
      return // Skip own blog for peer processing
    }
    if (autobase_cache.has(key)) {
      return
    }

    try {
      const peer_autobase = await setup_peer_autobase(key, key_buffer)

      if (peer_autobase.view.length > 0) {
        try {
          // Always check entry[0] for blog-init metadata
          const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
          if (validate_blog_init(init_block) && !get_subscribed_peers().includes(key)) {
            const { data } = init_block
            discovered_blogs.set(key, { ...data, key }) // Store init metadata
            autobase_cache.set(key, peer_autobase)
            // Note: peer profile drive is created in subscribe(), not here
            
            emitter.emit('update')
          }
        } catch (parseErr) {
          console.warn('Failed to parse peer init block:', parseErr.message)
        }
      } else {
        autobase_cache.set(key, peer_autobase)
      }
    } catch (err) {
      console.error('Error in peer-autobase-key handler:', err)
    }
  }

  store.on('peer-autobase-key', handle_peer_autobase_key)
}

// Create a post
async function create_post (title, content) {
  if (!blog_autobase.writable) {
    throw new Error('Blog is not writable. You may not have write access to this blog.')
  }

  const slug = title.toLowerCase().split(' ').join('_').replace(/[^a-z0-9_]/g, '')
  const filepath = `/posts/${slug}/index.md`
  await drive.put(filepath, b4a.from(`${title}\n\n${content}`))
  const device_key = b4a.toString(blog_autobase.local.key, 'hex')
  await blog_autobase.append({ type: 'blog-post', data: { filepath, created: Date.now(), device: device_key } })
  await blog_autobase.update()
  emitter.emit('update')
}

// Subscribe to peer
async function subscribe (key) {
  if (get_subscribed_peers().includes(key)) return true

  try {
    const peer_autobase = autobase_cache.get(key)
    if (!peer_autobase) return false

    const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
    const { data } = init_block
    
    // Check if drive already exists in cache ( this is for if we sub & unsub multiple times
    // in the same session )
    let peer_drive = drive_cache.get(key)
    if (!peer_drive) {
      const peer_drive_store = store.namespace(`peer-drive-${data.drive_key}`)
      peer_drive = create_autodrive({ store: peer_drive_store, bootstrap: b4a.from(data.drive_key, 'hex') })
      await peer_drive.ready()
      
      // Setup replication for peer drive store
      if (store.swarm) {
        function handle_peer_drive_replication (conn) {
          peer_drive_store.replicate(conn)
        }
        store.swarm.connections.forEach(handle_peer_drive_replication)
      }
    }
    
    // Setup peer profile drive if profile_drive_key exists
    if (data.profile_drive_key) {
      let peer_profile_drive = profile_cache.get(key)
      if (!peer_profile_drive) {
        const peer_profile_store = store.namespace(`peer-profile-${data.profile_drive_key}`)
        peer_profile_drive = create_autodrive({ store: peer_profile_store, bootstrap: b4a.from(data.profile_drive_key, 'hex') })
        
        // Setup replication BEFORE waiting for ready
        if (store.swarm) {
          function handle_peer_profile_replication (conn) {
            peer_profile_store.replicate(conn)
          }
          store.swarm.connections.forEach(handle_peer_profile_replication)
        }
        
        await peer_profile_drive.ready()
        profile_cache.set(key, peer_profile_drive)
      }
    }

    drive_cache.set(key, peer_drive)
    add_subscribed_peer(key)
    discovered_blogs.delete(key)
    
    await log_event('sub', { peer_key: key })
    console.log('Subscribed to peer:', key.slice(0, 16))
    
    emitter.emit('update')
    return true
  } catch (err) {
    console.error('[subscribe] Subscription failed:', err)
    return false
  }
}

// Get username from blog init data
async function get_blog_username () {
  if (!blog_autobase) return null
  try {
    await blog_autobase.update()
    if (blog_autobase.view.length === 0) return null
    const raw_data = await blog_autobase.view.get(0)
    if (!raw_data) return null
    const entry = JSON.parse(b4a.toString(raw_data))
    return entry.data?.username || null
  } catch (err) {
    return null
  }
}

// Get drive key from blog init data (unified function)
async function get_blog_drive_key (key_name) {
  if (!blog_autobase) return null
  try {
    await blog_autobase.update()
    if (blog_autobase.view.length === 0) return null
    const raw_data = await blog_autobase.view.get(0)
    if (!raw_data) return null
    const entry = JSON.parse(b4a.toString(raw_data))
    return entry.data?.[key_name] || null
  } catch (err) {
    return null
  }
}

// Convenience wrappers
const get_blog_profile_drive_key = () => get_blog_drive_key('profile_drive_key')
const get_blog_events_drive_key = () => get_blog_drive_key('events_drive_key')

// Get posts for any blog by key (unified function)
async function get_posts (key = null) {
  // Use own blog if no key provided
  const autobase = key ? autobase_cache.get(key) : blog_autobase
  const drive_instance = key ? drive_cache.get(key) : drive

  if (!autobase || !drive_instance) {
    return []
  }

  await autobase.update()
  const posts = []

  for (let i = 1; i < autobase.view.length; i++) { // Skip index 0 (blog-init)
    try {
      const raw_data = await autobase.view.get(i)
      if (!raw_data) continue
      const entry = JSON.parse(b4a.toString(raw_data))

      if (validate_blog_post(entry)) {
        const { data } = entry
        const content = await drive_instance.get(data.filepath)
        const device_name = data.device ? await get_device_name(data.device) : null

        if (content) {
          const lines = b4a.toString(content).split('\n')
          const title = lines[0] || 'Untitled'
          const postContent = lines.length > 2 ? lines.slice(2).join('\n') : ''
          posts.push({ ...data, title, content: postContent, device_name })
        } else {
          posts.push({ ...data, title: 'Untitled', content: '', device_name })
        }
      }
    } catch (err) {
      console.error(`Error reading entry ${i}:`, err.message)
    }
  }

  return posts.reverse()
}

// Get your posts
async function get_my_posts () {
  return get_posts() // No key = own blog
}

// Get peer blogs
async function get_peer_blogs () {
  const subscribed = get_subscribed_peers()
  const blogs = new Map()

  for (const key of subscribed) {
    try {
      const peer_autobase = autobase_cache.get(key)
      if (!peer_autobase) {
        continue
      }
      if (peer_autobase.view.length === 0) {
        continue
      }

      const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
      if (!validate_blog_init(init_block)) {
        continue
      }

      const { data } = init_block
      let peer_drive = drive_cache.get(key)
      if (!peer_drive) {
        const peer_files_store = store.namespace(`peer-files-${data.drive_key}`)
        peer_drive = create_autodrive({ store: peer_files_store, bootstrap: b4a.from(data.drive_key, 'hex') })
        drive_cache.set(key, peer_drive)
      }

      await peer_drive.ready()
      blogs.set(key, {
        key,
        posts: await get_posts(key), // Use unified function
        username: data.username,
        title: data.title
      })
    } catch (err) {
      console.error('Error for peer:', key.slice(0, 16), err.message)
    }
  }
  return blogs
}

// Create default profile
async function create_default_profile (username) {
  const default_avatar = `<svg><text x="50%" y="50%" font-size="120" text-anchor="middle" dominant-baseline="middle">ðŸ‘¤</text></svg>`
  
  await profile_drive.put('/avatar.svg', b4a.from(default_avatar))
  await profile_drive.put('/profile.json', b4a.from(JSON.stringify({
    name: username,
    avatar: '/avatar.svg'
  })))
}

// Upload avatar image
async function upload_avatar (imageData, filename) {
  if (!profile_drive) {
    throw new Error('Profile drive not initialized')
  }
  
  // Get file extension from filename
  const ext = filename.split('.').pop().toLowerCase()
  const avatar_path = `/avatar.${ext}`
  
  // Store the image file
  await profile_drive.put(avatar_path, b4a.from(imageData))
  
  // Update profile.json to point to the new avatar
  const profile = await get_profile()
  const updated_profile = {
    ...profile,
    avatar: avatar_path
  }
  
  await profile_drive.put('/profile.json', b4a.from(JSON.stringify(updated_profile)))
  emitter.emit('update')
}

// Get profile data
async function get_profile (key = null) {
  const profile_instance = key ? profile_cache.get(key) : profile_drive
  if (!profile_instance) return null
  
  try {
    await profile_instance.ready()  
    const profile_data = await profile_instance.get('/profile.json')
    if (!profile_data) return null
    return JSON.parse(b4a.toString(profile_data))
  } catch (err) {
    console.error('Error getting profile:', err)
    return null
  }
}

// Get avatar content from drive
async function get_avatar_content (key = null) {
  const profile_instance = key ? profile_cache.get(key) : profile_drive
  if (!profile_instance) return null
  
  try {
    await profile_instance.ready()
    
    // Get profile to find avatar path
    const profile = await get_profile(key)
    if (!profile || !profile.avatar) return null
    
    const avatar_data = await profile_instance.get(profile.avatar)
    if (!avatar_data) return null
    
    // For SVG files, return as text
    if (profile.avatar.endsWith('.svg')) {
      return b4a.toString(avatar_data)
    }
    
    // For image files, return as data URL
    const ext = profile.avatar.split('.').pop().toLowerCase()
    const mimeType = ext === 'jpg' || ext === 'jpeg' ? 'image/jpeg' : `image/${ext}`
    const base64 = b4a.toString(avatar_data, 'base64')
    return `data:${mimeType};base64,${base64}`
  } catch (err) {
    return null
  }
}

// Log event to events drive
async function log_event (type, data) {
  if (!events_drive) {
    console.warn(`[log_event] Cannot log ${type} event: events_drive not initialized`)
    return
  }
  
  try {
    const event = {
      type,
      data,
      meta: {
        time: Date.now()
      }
    }
    
    const event_path = `/events/${event.meta.time}-${type}.json`
    await events_drive.put(event_path, b4a.from(JSON.stringify(event)))
    console.log(`[log_event] Logged ${type} event to events drive`)
  } catch (err) {
    console.error('Error logging event:', err)
  }
}

// Get all events from events drive
async function get_events () {
  if (!events_drive) return []
  
  try {
    await events_drive.ready()
    const events = []
    const files = await events_drive.list('/events')
    
    for (const file of files) {
      try {
        const content = await events_drive.get(file)
        if (content) {
          events.push(JSON.parse(b4a.toString(content)))
        }
      } catch (err) {
        console.error('Error reading event file:', file, err)
      }
    }
    
    return events.sort((a, b) => a.meta.time - b.meta.time)
  } catch (err) {
    console.error('Error getting events:', err)
    return []
  }
}

// Get paired devices from events drive (calculates active devices from add/remove events)
async function get_paired_devices () {
  const events = await get_events()
  const devices_map = new Map()
  let device_counter = 0 // Start at 0 so bootstrap device is Device 1
  
  // Process events in order to track add/remove
  for (const event of events) {
    if (event.type === 'add') {
      const device_id = event.data.metadata_writer
      device_counter++
      const device_name = `Device ${device_counter}`
      devices_map.set(device_id, {
        name: device_name,
        metadata_writer: event.data.metadata_writer,
        drive_writer: event.data.drive_writer,
        profile_writer: event.data.profile_writer,
        events_writer: event.data.events_writer,
        timestamp: event.meta.time,
        added_date: new Date(event.meta.time).toLocaleString()
      })
    } else if (event.type === 'remove') {
      const device_id = event.data.metadata_writer
      devices_map.delete(device_id)
    }
  }
  
  return Array.from(devices_map.values())
}

// Get device name by metadata writer key
async function get_device_name (metadata_writer_key) {
  const devices = await get_paired_devices()
  const device = devices.find(d => d.metadata_writer === metadata_writer_key)
  return device ? device.name : null
}

// Remove device by removing writer access from all drives
async function remove_device (device) {
  try {
    // Remove from metadata autobase
    await blog_autobase.append({ 
      type: 'removeWriter', 
      data: { key: device.metadata_writer } 
    })
    await blog_autobase.update()
    
    // Remove from drive autodrive
    await drive.remove_writer(device.drive_writer)
    
    // Remove from profile autodrive if it exists
    if (profile_drive) {
      await profile_drive.remove_writer(device.profile_writer)
    }
    
    // Remove from events autodrive if it exists
    if (events_drive) {
      await events_drive.remove_writer(device.events_writer)
    }
    
    // Log the removal event
    await log_event('remove', {
      metadata_writer: device.metadata_writer,
      drive_writer: device.drive_writer,
      profile_writer: device.profile_writer,
      events_writer: device.events_writer
    })
    
    console.log('Device removed successfully')
    emitter.emit('update')
    return true
  } catch (err) {
    console.error('Error removing device:', err)
    return false
  }
}

// Get raw data from any data structure
async function get_raw_data (type) {
  if (type === 'metadata') {
    if (!blog_autobase) return 'No metadata autobase'
    await blog_autobase.update()
    const entries = []
    for (let i = 0; i < blog_autobase.view.length; i++) {
      try {
        entries.push(`[${i}] ${b4a.toString(await blog_autobase.view.get(i))}`)
      } catch (err) {
        entries.push(`[${i}] Error: ${err.message}`)
      }
    }
    return entries.join('\n')
  }
  
  const target = type === 'posts' ? drive : (type === 'profile' ? profile_drive : events_drive)
  if (!target) return `No ${type} autodrive`
  await target.ready()
  const files = []
  
  // Use correct directory for each type
  const list_path = type === 'events' ? '/events' : '/'
  
  try {
    for (const file of await target.list(list_path)) {
      try {
        const content = await target.get(file)
        files.push(`${file}: ${content ? b4a.toString(content) : 'null'}`)
      } catch (err) {
        files.push(`${file}: Error: ${err.message}`)
      }
    }
  } catch (err) {
    files.push(`List error: ${err.message}`)
  }
  return files.join('\n\n')
}

// Create invite for pairing
async function create_invite (swarm) {
  const pairing_helper = require('../pairing-helper')
  const { invite_code, invite, profile_drive_key } = await pairing_helper.create_invite(
    drive.base.key,
    blog_autobase.key,
    profile_drive.base.key
  )

  await pairing_helper.setup_member({ drive, blog_autobase, profile_drive, events_drive, swarm, invite, profile_drive_key })

  return invite_code
}

// Unified function to set drive and store
function set_drive (type, drive, store_instance) {
  if (type === 'profile') {
    profile_drive = drive
    profile_store = store_instance
  } else if (type === 'events') {
    events_drive = drive
    events_store = store_instance
    
    // Setup event sync listeners
    setup_events_sync_listeners()
  }
  
  // Note: Replication is handled by pairing connection handler in web-peer
  emitter.emit('update')
}

// Convenience wrappers
const set_profile_drive = (drive, store_instance) => set_drive('profile', drive, store_instance)
const set_events_drive = (drive, store_instance) => set_drive('events', drive, store_instance)

module.exports = {
  init_blog,
  create_post,
  create_invite,
  subscribe,
  get_posts,
  get_my_posts,
  get_peer_blogs,
  get_blog_username,
  get_blog_profile_drive_key,
  get_blog_events_drive_key,
  get_profile,
  get_avatar_content,
  get_raw_data,
  upload_avatar,
  set_profile_drive,
  set_events_drive,
  log_event,
  get_events,
  get_paired_devices,
  get_device_name,
  remove_device,
  get_discovered_blogs: () => discovered_blogs, // Blogs in explore tab
  get_my_core_key: () => blog_autobase?.key,
  get_local_key: () => blog_autobase ? b4a.toString(blog_autobase.local.key, 'hex') : null,
  get_drive: () => drive,
  get_profile_drive: () => profile_drive,
  get_autobase_key: () => blog_autobase ? b4a.toString(blog_autobase.key, 'hex') : null,
  get_autobase: () => blog_autobase,
  get_metadata_store: () => metadata_store,
  get_drive_store: () => drive_store,
  get_profile_store: () => profile_store,
  get_events_store: () => events_store,
  on_update: handle_update_callback,
  unsubscribe: handle_unsubscribe
}

function handle_update_callback (cb) {
  return emitter.on('update', cb)
}

async function handle_unsubscribe (key) {
  remove_subscribed_peer(key)
  
  // Add back to discovered_blogs (don't delete autobase_cache - keep peer discoverable)
  const peer_autobase = autobase_cache.get(key)
  if (peer_autobase && peer_autobase.view.length > 0) {
    try {
      const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
      if (init_block.data) {
        discovered_blogs.set(key, { ...init_block.data, key })
      }
    } catch (err) {
      console.error('Error restoring to explore:', err)
    }
  }
  
  // Log unsubscribe event
  await log_event('unsub', { peer_key: key })
  console.log('Unsubscribed from peer:', key.slice(0, 16))
  
  emitter.emit('update')
}
