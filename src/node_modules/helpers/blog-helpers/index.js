// Simple P2P blog helper
const Autobase = require('autobase')
const b4a = require('b4a')
const { create_autodrive } = require('../../autodrive')

// emitter
function make_emitter(state = {}) {
  return { on, off, emit }
  function on(type, callback) { (state[type] = state[type] || []).push(callback) }
  function off(type, callback) { (state[type] = state[type] || [])[state[type].indexOf(callback)] = undefined }
  function emit(type, data) { (state[type] = state[type] || []).map(f => f && f(data)) }
}

// Global state
let store, blog_autobase, drive, metadata_store, drive_store
const discovered_blogs = new Map() // Blogs available in explore tab
const autobase_cache = new Map()
const drive_cache = new Map()
const emitter = make_emitter()

// Validation functions
function validate_blog_init(entry) {
  return entry && 
         entry.type === 'blog-init' && 
         typeof entry.username === 'string' && 
         typeof entry.title === 'string' && 
         typeof entry.drive_key === 'string'
}

function validate_blog_post(entry) {
  return entry && 
         entry.type === 'blog-post' && 
         typeof entry.filepath === 'string' && 
         typeof entry.created === 'number'
}

// Local storage helpers
const get_subscribed_peers = () => {
  try { return JSON.parse(localStorage.getItem('subscribed_peers') || '[]') } catch { return [] }
}
const add_subscribed_peer = key => {
  const peers = get_subscribed_peers()
  if (!peers.includes(key)) {
    peers.push(key)
    localStorage.setItem('subscribed_peers', JSON.stringify(peers))
  }
}
const remove_subscribed_peer = key => {
  localStorage.setItem('subscribed_peers', JSON.stringify(get_subscribed_peers().filter(k => k !== key)))
}

// Create autobase (new or paired)
function create_blog_autobase(metadata_store, key = null) {
  return new Autobase(metadata_store, key, {
    valueEncoding: 'json',
    open: (store) => store.get({ name: 'blog-view' }),
    apply: async (batch, view, base) => {
      for (const entry of batch) {
        if (entry.value?.addWriter) {
          const writer_key = b4a.from(entry.value.addWriter, 'hex')
          await base.addWriter(writer_key, { isIndexer: true })
        } else if (entry.value) {
          await view.append(JSON.stringify(entry.value))
        }
      }
    }
  })
}

// Setup peer autobase
async function setup_peer_autobase(key, key_buffer) {
  const peer_metadata_store = store.namespace(`peer-metadata-${key.slice(0, 16)}`)
  const peer_autobase = create_blog_autobase(peer_metadata_store, key_buffer)
  await peer_autobase.ready()
  
  // Wait for init blog to replicate if needed
  if (peer_autobase.view.length === 0) {
    await new Promise(resolve => peer_autobase.once('update', resolve))
  }
  
  peer_autobase.on('update', async () => {
    if (peer_autobase.view.length > 0) {
      try {
        const latest_index = peer_autobase.view.length - 1
        const raw_data = await peer_autobase.view.get(latest_index)
        const latest_entry = JSON.parse(b4a.toString(raw_data))
        
        if (validate_blog_init(latest_entry) && !get_subscribed_peers().includes(key)) {
          discovered_blogs.set(key, { ...latest_entry, key })
          autobase_cache.set(key, peer_autobase)
          emitter.emit('update')
        } else if (validate_blog_post(latest_entry)) {
          store.emit('feed', peer_autobase)
        }
      } catch (err) {
        console.error('Error processing update:', err)
      }
    }
  })
  
  return peer_autobase
}

// Restore subscribed peers on startup
async function restore_subscribed_peers() {
  for (const key of get_subscribed_peers()) {
    try {
      const peer_autobase = await setup_peer_autobase(key, b4a.from(key, 'hex'))
      if (peer_autobase.view.length > 0) {
        autobase_cache.set(key, peer_autobase)
        const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
        const peer_drive_store = store.namespace(`peer-drive-${init_block.drive_key.slice(0, 16)}`)
        drive_cache.set(key, create_autodrive(peer_drive_store, b4a.from(init_block.drive_key, 'hex')))
      }
    } catch (err) {
      console.error('Error restoring peer:', key.slice(0, 16) + '...', err)
    }
  }
}

// Initialize blog - join or create
async function init_blog(store_instance, username, drive_key = null, autobase_key = null, _metadata_store = null, _drive_store = null) {
  store = store_instance
  
  // Use provided stores for shared access, or create new ones for new blogs
  metadata_store = _metadata_store || store.namespace('blog-metadata')
  drive_store = _drive_store || store.namespace('blog-files')
  
  // Create autobase and drive based on whether keys are provided
  blog_autobase = create_blog_autobase(metadata_store, autobase_key)
  drive = create_autodrive(drive_store, drive_key)
  
  await Promise.all([blog_autobase.ready(), drive.ready()])
  
  if (!autobase_key && blog_autobase.view.length === 0) {
    // Create init blog for new identity
    const init_data = {
      type: 'blog-init',
      drive_key: b4a.toString(drive.base.key, 'hex'),
      title: `${username}'s Blog`,
      username
    }
    await blog_autobase.append(init_data)
    await blog_autobase.update()
  }
  
  // Setup replication for new blogs
  if (!autobase_key && store.swarm) {
    const replicate = (conn) => {
      metadata_store.replicate(conn)
      drive_store.replicate(conn)
    }
    store.swarm.on('connection', replicate)
    store.swarm.connections.forEach(replicate)
  }
  
  setup_event_handlers()
  await restore_subscribed_peers()
  emitter.emit('update')
}

// Setup common event handlers
function setup_event_handlers() {
  blog_autobase.on('append', () => emitter.emit('update'))
  blog_autobase.on('update', () => emitter.emit('update'))
  store.on('feed', () => emitter.emit('update'))
  
  store.on('peer-autobase-key', async ({ key, key_buffer }) => {
    if (key === b4a.toString(blog_autobase.key, 'hex')) return
    if (autobase_cache.has(key)) {
      console.log('Peer already discovered, skipping:', key.slice(0, 16) + '...')
      return
    }
    
    try {
      const peer_autobase = await setup_peer_autobase(key, key_buffer)
      
      if (peer_autobase.view.length > 0) {
        try {
          const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
          if (validate_blog_init(init_block) && !get_subscribed_peers().includes(key)) {
            discovered_blogs.set(key, { ...init_block, key })
            autobase_cache.set(key, peer_autobase)
            emitter.emit('update')
          }
        } catch (parseErr) {
          console.warn('Failed to parse peer init block:', parseErr.message)
        }
      } else {
        autobase_cache.set(key, peer_autobase)
      }
    } catch (err) {
      console.error('Error in peer-autobase-key handler:', err)
    }
  })
}

// Create a post
async function create_post(title, content) {
  if (!blog_autobase.writable) {
    throw new Error('Blog is not writable. You may not have write access to this blog.')
  }
  
  const slug = title.toLowerCase().split(' ').join('_').replace(/[^a-z0-9_]/g, '')
  const filepath = `/posts/${slug}/index.md`
  await drive.put(filepath, b4a.from(`${title}\n\n${content}`))
  await blog_autobase.append({ type: 'blog-post', filepath, created: Date.now() })
  await blog_autobase.update()
  emitter.emit('update')
}

// Subscribe to peer
async function subscribe(key) {
  if (get_subscribed_peers().includes(key)) return true
  
  try {
    const peer_autobase = autobase_cache.get(key)
    if (!peer_autobase) return false
    
    const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
    const peer_drive_store = store.namespace(`peer-drive-${init_block.drive_key.slice(0, 16)}`)
    const peer_drive = create_autodrive(peer_drive_store, b4a.from(init_block.drive_key, 'hex'))
    
    // Setup replication for peer drive store
    if (store.swarm) {
      store.swarm.connections.forEach(conn => peer_drive_store.replicate(conn))
    }
    
    drive_cache.set(key, peer_drive)
    add_subscribed_peer(key)
    discovered_blogs.delete(key) // Remove from explore tab when subscribed
    emitter.emit('update')
    return true
  } catch (err) {
    console.error('Subscription failed:', err)
    return false
  }
}

// Get posts for any blog by key (unified function)
async function get_posts(key = null) {
  // Use own blog if no key provided
  const autobase = key ? autobase_cache.get(key) : blog_autobase
  const drive_instance = key ? drive_cache.get(key) : drive
  
  if (!autobase || !drive_instance) return []
  
  await autobase.update()
  const posts = []
  
  for (let i = 1; i < autobase.view.length; i++) {
    try {
      const raw_data = await autobase.view.get(i)
      if (!raw_data) continue
      const entry = JSON.parse(b4a.toString(raw_data))
      
      if (validate_blog_post(entry)) {
        const content = await drive_instance.get(entry.filepath)
        
        if (content) {
          const lines = b4a.toString(content).split('\n')
          const title = lines[0] || 'Untitled'
          const postContent = lines.length > 2 ? lines.slice(2).join('\n') : ''
          posts.push({ ...entry, title, content: postContent })
        } else {
          posts.push({ ...entry, title: 'Untitled', content: '' })
        }
      }
    } catch (err) {
      console.error(`Error reading entry ${i}:`, err.message)
    }
  }
  
  return posts.reverse()
}

// Get your posts
async function get_my_posts() {
  return get_posts() // No key = own blog
}

// Get peer blogs
async function get_peer_blogs() {
  const blogs = new Map()
  
  for (const key of get_subscribed_peers()) {
    try {
      const peer_autobase = autobase_cache.get(key)
      if (!peer_autobase || peer_autobase.view.length === 0) continue
      
      const init_block = JSON.parse(b4a.toString(await peer_autobase.view.get(0)))
      if (!validate_blog_init(init_block)) continue
      
      let peer_drive = drive_cache.get(key)
      if (!peer_drive) {
        const peer_files_store = store.namespace(`peer-files-${init_block.drive_key.slice(0, 16)}`)
        peer_drive = create_autodrive(peer_files_store, b4a.from(init_block.drive_key, 'hex'))
        drive_cache.set(key, peer_drive)
      }
      
      await peer_drive.ready()
      blogs.set(key, {
        key,
        posts: await get_posts(key), // Use unified function
        username: init_block.username,
        title: init_block.title
      })
    } catch (err) {
      // Silent error handling - peer might not be available
    }
  }
  return blogs
}

// Create invite for pairing
async function create_invite(swarm) {
  const pairing_helper = require('../pairing-helper')
  const { invite_code, invite } = await pairing_helper.create_invite(
    drive.base.key,
    blog_autobase.key,
    swarm
  )
  
  await pairing_helper.setup_member(drive, blog_autobase, swarm, invite)
  
  return invite_code
}

module.exports = {
  init_blog, create_post, create_invite, subscribe, get_posts, get_my_posts, get_peer_blogs,
  get_discovered_blogs: () => discovered_blogs, // Blogs in explore tab
  get_my_core_key: () => blog_autobase?.key,
  get_drive: () => drive,
  get_autobase_key: () => blog_autobase ? b4a.toString(blog_autobase.key, 'hex') : null,
  get_autobase: () => blog_autobase,
  get_metadata_store: () => metadata_store,
  get_drive_store: () => drive_store,
  on_update: cb => emitter.on('update', cb),
  unsubscribe: key => { 
    remove_subscribed_peer(key)
    drive_cache.delete(key)
    autobase_cache.delete(key)
    emitter.emit('update')
  }
}