const Autobase = require('autobase')
const Hyperdrive = require('hyperdrive')
const b4a = require('b4a')
const messages = require('autobase/lib/messages')

module.exports = { create_autodrive, get_local_core }

function create_autodrive (options) {
  const { store, bootstrap, opts = {} } = options
  const emitter = make_emitter()
  const state = {
    store,
    drive: null,
    bootstrap,
    readers: new Set(),
    writers: new Set(),
    opts,
    base: null,
    view_ready: false
  }

  state.base = new Autobase(store, bootstrap, {
    valueEncoding: 'json',
    open: handle_autobase_open,
    apply: handle_autobase_apply,
    close: handle_autobase_close,
    ackInterval: opts.ack_interval || 1000,
    ackThreshold: opts.ack_threshold || 0,
    fastForward: false
  })

  state.base.on('update', handle_base_update)

  async function handle_base_update () {
    try {
      if (state.base.view && state.base.view.drive) {
        state.drive = state.base.view.drive
        state.view_ready = true
      }
      emitter.emit('update')
    } catch (err) {
      console.error('Error on base update:', err)
    }
  }

  const api = {
    get base () { return state.base },
    on,
    off,
    emit,
    ready,
    close,
    put,
    del,
    get,
    list,
    download,
    add_writer,
    add_reader,
    remove_reader,
    remove_writer,
    get_readers,
    get_writers,
    is_reader,
    is_writer,
    exists,
    replicate
  }

  return api

  /***************************************
INTERNAL FUNCTIONS
***************************************/
  function handle_autobase_open (store) {
    const drive_store = store.base.store.namespace('autodrive')
    const drive = new Hyperdrive(drive_store)
    return { drive }
  }

  async function handle_autobase_apply (nodes, view, base) {
    await view.drive.ready()
    const batch = view.drive.batch()

    for (const node of nodes) {
      const { type, data = {} } = node.value || {}
      if (!type) continue

      try {
        if (type === 'put') {
          const buffer = b4a.from(data.content, 'base64')
          await batch.put(data.path, buffer)
        } else if (type === 'del') {
          await batch.del(data.path)
        } else if (type === 'add_writer') {
          const key = b4a.from(data.key, 'hex')
          await base.addWriter(key, { indexer: data.is_indexer })
          state.writers.add(data.key)
        } else if (type === 'add_reader') {
          state.readers.add(data.key)
        } else if (type === 'remove_writer') {
          const key = b4a.from(data.key, 'hex')
          await base.removeWriter(key)
          state.writers.delete(data.key)
        } else if (type === 'remove_reader') {
          state.readers.delete(data.key)
        }
      } catch (err) {
        console.error('Error applying node:', err)
      }
    }

    await batch.flush()
    await batch.close()
  }

  async function handle_autobase_close (view) {
    if (view.drive) await view.drive.close()
  }

  function on (event, listener) {
    emitter.on(event, listener)
  }

  function off (event, listener) {
    emitter.off(event, listener)
  }

  function emit (event, ...args) {
    emitter.emit(event, ...args)
  }

  async function ready () {
    await state.base.ready()
    state.drive = state.base.view.drive
    await state.drive.ready()
    state.view_ready = true
  }

  async function close () {
    await state.base.close()
  }

  async function put (path, content) {
    await ready()
    await state.base.append({
      type: 'put',
      data: {
        path,
        content: b4a.toString(content, 'base64')
      }
    })
    await state.base.update()
  }

  async function del (path) {
    await ready()
    await state.base.append({ type: 'del', data: { path } })
    await state.base.update()
  }

  async function get (path, opts) {
    await ready()
    await state.base.update()
    return state.drive.get(path, opts)
  }

  async function list (folder = '/', opts = {}) {
    await ready()
    await state.base.update()
    const entries = []
    for await (const entry of state.drive.list(folder, { ...opts, recursive: false })) {
      entries.push(entry.key)
    }
    return entries
  }

  async function download (folder = '/', opts) {
    await ready()
    if (typeof folder === 'object') {
      opts = folder
      folder = '/'
    }

    const dls = []
    const entry = (!folder || folder.endsWith('/')) ? null : await state.drive.entry(folder)

    if (entry) {
      const b = entry.value.blob
      if (!b) return
      const blobs = await state.drive.getBlobs()
      await blobs.core.download({ start: b.blockOffset, length: b.blockLength }).downloaded()
      return
    }

    // Download the directory listing first
    for await (const _ of state.drive.list(folder, opts)) {}

    // Then download all blobs
    for await (const entry of state.drive.list(folder, opts)) {
      const b = entry.value.blob
      if (!b) continue
      const blobs = await state.drive.getBlobs()
      dls.push(blobs.core.download({ start: b.blockOffset, length: b.blockLength }))
    }

    await Promise.allSettled(dls.map(function (r) { return r.downloaded() }))
  }

  async function add_writer (key, opts = {}) {
    const key_str = typeof key === 'string' ? key : key.toString('hex')
    const is_indexer = opts.is_indexer === undefined ? true : !!opts.is_indexer
    await state.base.append({
      type: 'add_writer',
      data: { key: key_str, is_indexer }
    })
    await state.base.update()
  }

  async function add_reader (key) {
    const key_str = typeof key === 'string' ? key : key.toString('hex')
    await state.base.append({ type: 'add_reader', data: { key: key_str } })
    await state.base.update()
  }

  async function remove_reader (key) {
    const key_str = typeof key === 'string' ? key : key.toString('hex')
    await state.base.append({ type: 'remove_reader', data: { key: key_str } })
    await state.base.update()
  }

  async function remove_writer (key) {
    const key_str = typeof key === 'string' ? key : key.toString('hex')
    await state.base.append({ type: 'remove_writer', data: { key: key_str } })
    await state.base.update()
  }

  function get_readers () { return Array.from(state.readers) }
  function get_writers () { return Array.from(state.writers) }

  function is_reader (key) {
    const key_str = typeof key === 'string' ? key : key.toString('hex')
    return state.readers.has(key_str)
  }

  function is_writer (key) {
    const key_str = typeof key === 'string' ? key : key.toString('hex')
    return state.writers.has(key_str) || key_str === state.base.key.toString('hex')
  }

  async function exists (path) {
    await ready()
    try {
      const entry = await state.drive.entry(path)
      return !!entry
    } catch {
      return false
    }
  }

  function replicate (stream_or_initiator, opts = {}) {
    return state.store.replicate(stream_or_initiator, opts)
  }
}

/***************************************
GENERAL HELPER FUNCTIONS
***************************************/

/***************************************
GET LOCAL CORE
***************************************/
function get_local_core (options) {
  const { store, handlers, encryptionKey } = options
  const opts = {
    ...handlers,
    compat: false,
    active: false,
    exclusive: true,
    valueEncoding: messages.OplogMessage,
    encryptionKey
  }
  return opts.keyPair ? store.get(opts) : store.get({ ...opts, name: 'local' })
}

/***************************************
MAKE EMITTER
***************************************/
function make_emitter (state = {}) {
  return { on, off, emit }
  function on (type, callback) { (state[type] = state[type] || []).push(callback) }
  function off (type, callback) { (state[type] = state[type] || [])[state[type].indexOf(callback)] = undefined }
  function emit (type, ...args) {
    function handle_callback (f) {
      return f && f(...args)
    }
    return (state[type] = state[type] || []).map(handle_callback)
  }
}
