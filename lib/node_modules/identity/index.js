// Identity module which is app independent
// This module handles: keypairs, pairing, networking, data structures
// Doesnt contain app-specific things
// Exports a single constructor function that returns {make, load} API

const b4a = require('b4a')
const Corestore = require('corestore')

// Environment-based storage
// because we have to deal with bot the cli & web peers
const is_cli = typeof globalThis.open === 'undefined'

const Hyperswarm = require('hyperswarm')
const Protomux = require('protomux')

// Browser-only modules (would break in CLI environment)
const RAW = is_cli ? null : require('random-access-web')
const DHT = require('@hyperswarm/dht-relay')
const Stream = require('@hyperswarm/dht-relay/ws')
const HyperWebRTC = is_cli ? null : require('hyper-webrtc')
const { create_mnemonic_keypair, save, load: load_mnemonic } = require('../crypto-helpers')
const { identity_exchange_protocol } = require('../protocol-helpers')


// Emitter helper
function make_emitter (state = {}) {
  return { on, off, emit }
  function on (type, callback) { (state[type] = state[type] || []).push(callback) }
  function off (type, callback) { (state[type] = state[type] || [])[state[type].indexOf(callback)] = undefined }
  function emit (type, data) {
    function handle_callback (f) {
      return f && f(data)
    }
    return (state[type] = state[type] || []).map(handle_callback)
  }
}

// Browser networking setup
async function start_networking (options = {}) {
  const name = options.name || 'peer'
  const topic = options.topic // App must provide topic
  const store_name = options.store_name || name // App can provide custom store name
  const get_primary_key = options.get_primary_key
  const get_primary_structure = options.get_primary_structure

  if (!topic) {
    throw new Error('start_networking requires a topic parameter')
  }

  // Use file system for CLI, indexed DB for browser
  const store = is_cli ? 
    new Corestore(`./storage-${store_name}`) : 
    new Corestore(RAW(store_name))

  await store.ready()

  // CLI: Use same networking pattern as bare-peer
  if (is_cli) {
    const seedphrase = await load_mnemonic(name)
    const mnemonic_data = seedphrase
      ? await create_mnemonic_keypair({ namespace: 'noisekeys', name: 'noise', mnemonic: seedphrase })
      : await create_mnemonic_keypair({ namespace: 'noisekeys', name: 'noise' })

    if (!seedphrase) await save(mnemonic_data.mnemonic, name)
    
    const swarm = new Hyperswarm({ key_pair: mnemonic_data.keypair })
    
    // Use bare-peer connection handling pattern
    swarm.on('connection', (socket, info) => {
      const peer_id = info.publicKey.toString('hex')
      console.log(`Connected to peer: ${peer_id.slice(0, 8)}`)
      
      const mux = new Protomux(socket)
      
      const handlers = {
        on_protocol: async (message, send) => {
          if (message.data && message.data.name) {
            console.log(`Discovered peer: ${message.data.name}`)
          }
        },
        on_feedkey: async ({ key_buffer }) => {
          const hex_key = b4a.toString(key_buffer, 'hex')
          console.log(`Received key: ${hex_key.slice(0, 8)}`)
          store.emit('peer-autobase-key', { key: hex_key, key_buffer })
        }
      }
      
      function handle_protocol_init (send) {
        send({
          type: 'protocol',
          data: {
            name: name,
            mode: 'native',
            device_public_key: mnemonic_data.keypair.publicKey.toString('hex')
          }
        })
        
        if (get_primary_key) {
          const key = get_primary_key()
          if (key) send({ type: 'feedkey', data: key })
        }
      }
      
      const setup_protocol = identity_exchange_protocol(handlers, handle_protocol_init, {
        peer_mode: 'native',
        label: '[CLI]'
      })
      
      const channel = setup_protocol(mux)
      channel.open()
      
      store.replicate(socket)
    })
    
    const discovery = swarm.join(topic, { server: true, client: true })
    store.swarm = swarm
    
    return { store, swarm, dht: null, cleanup: () => swarm.destroy() }
  }

  // Browser: Original WebSocket relay code
  const is_dev = location.hostname === 'localhost' || location.hostname.startsWith('192.') || location.hostname.startsWith('10.')
  const relay_url = options.relay || (is_dev ? 'ws://localhost:8080' : 'wss://relay-production-9c0e.up.railway.app')

  await store.ready()

  return new Promise((resolve, reject) => {
    const socket = new WebSocket(relay_url)

    function handle_socket_error (err) {
      const errorMessage = err.message || err.toString() || ''
      if (errorMessage.includes('Invalid URL') || errorMessage.includes('URL scheme') || errorMessage.includes('ERR_INVALID_URL')) {
        reject(new Error(`Invalid relay URL: ${relay_url}`))
      } else {
        resolve({ store, swarm: null, dht: null, cleanup: () => {} })
      }
    }

    socket.addEventListener('error', handle_socket_error)
    socket.addEventListener('close', () => {})

    async function handle_socket_open () {
      try {
        if (socket.readyState !== WebSocket.OPEN) {
          console.error('Socket not ready:', socket.readyState)
          return
        }

        const seedphrase = await load_mnemonic(name)
        const mnemonic_data = seedphrase
          ? await create_mnemonic_keypair({ namespace: 'noisekeys', name: 'noise', mnemonic: seedphrase })
          : await create_mnemonic_keypair({ namespace: 'noisekeys', name: 'noise' })

        if (!seedphrase) await save(mnemonic_data.mnemonic, name)

        const stream = new Stream(true, socket)
        const dht = new DHT(stream)
        const swarm = new Hyperswarm({ dht, key_pair: mnemonic_data.keypair })

        function handle_swarm_connection (relay, details) {
          if (!relay.userData) relay.userData = null
          const mux = new Protomux(relay)

          async function handle_protocol_message (message, send, current_peer_mode) {
            if (message.data.relay_url) {
              if (!window.discovered_relays) window.discovered_relays = new Set()
              window.discovered_relays.add(message.data.relay_url)
            }

            if (message.data.mode === 'browser' && current_peer_mode === 'browser') {
              const stream = HyperWebRTC.from(relay, { initiator: relay.isInitiator })

              stream.on('open', () => {
                console.log('WebRTC connection established')
                const primary_key = get_primary_key ? get_primary_key() : null
                if (primary_key) send({ type: 'feedkey', data: primary_key })
                store.replicate(stream)
              })

              stream.on('error', (err) => {
                if (!err || (!err.message?.includes('Abort') && !err.message?.includes('closed'))) {
                  console.warn('WebRTC error details:', {
                    message: err?.message,
                    code: err?.code,
                    stack: err?.stack,
                    fullError: err
                  })
                }
              })
            } else if (message.data.mode === 'native') {
              const primary_key = get_primary_key ? get_primary_key() : null
              if (primary_key) send({ type: 'feedkey', data: primary_key })
              store.replicate(relay)
            }
          }

          async function handle_feedkey_message ({ key_buffer }) {
            const hex_key = b4a.toString(key_buffer, 'hex')
            store.emit('peer-autobase-key', { key: hex_key, key_buffer })
          }

          const handlers = {
            on_protocol: handle_protocol_message,
            on_feedkey: handle_feedkey_message
          }

          function handle_protocol_init (send) {
            send({
              type: 'protocol',
              data: {
                name,
                mode: 'browser',
                device_public_key: b4a.toString(mnemonic_data.keypair.publicKey, 'hex'),
                relay_url: relay_url
              }
            })
          }

          const setup_protocol = identity_exchange_protocol(handlers, handle_protocol_init, {
            peer_mode: 'browser',
            label: '[browser-peer]'
          })

          const identity_channel = setup_protocol(mux)
          identity_channel.open()

          store.on('peer-add', (peer) => {
            if (get_primary_structure) {
              const structure = get_primary_structure()
              if (structure && structure.key) {
                store.emit('peer-autobase-key', {
                  key: b4a.toString(structure.key, 'hex'),
                  key_buffer: structure.key
                })
              }
            }
          })

          relay.on('error', (err) => {
            if (!err.message?.includes('Duplicate connection')) {
              console.warn('Relay error:', err.message)
            }
          })
        }

        swarm.on('connection', handle_swarm_connection)

        console.log('Joining swarm')
        const discovery = swarm.join(topic, { server: true, client: true })

        const join_interval = setInterval(() => {
          swarm.join(topic, { server: true, client: true })
            .flushed()
            .catch((err) => console.warn('Join warning:', err.message))
        }, 5000)

        store.swarm = swarm

        resolve({ 
          store, 
          swarm, 
          dht, 
          cleanup: () => clearInterval(join_interval)
        })

        discovery.flushed()
          .then(() => console.log('Swarm joined'))
          .catch((err) => console.warn('Flush warning:', err.message))
      } catch (error) {
        console.error('Error in socket open handler:', error)
        reject(error)
      }
    }

    socket.addEventListener('open', handle_socket_open)
  })
}

// Identity module constructor
// Returns identity instance API directly (no make/load needed for single user apps)
module.exports = identity

function identity (config = {}) {
  const {
    name = 'browser-peer',
    relay = null,
    topic = null
  } = config

  // Create corestore for this identity
  const store = is_cli ? 
    new Corestore(`./storage-identity-${name}`) : 
    new Corestore(RAW(`identity-${name}`))

  // Global state for this identity instance
  let events_drive, events_store, ds_manager, pairing_manager, swarm, dht, keypair, networking_ready = false
  const emitter = make_emitter()
  
  // Store config for later use
  const vault_config = config

  // Log event (generic event logging for apps)
  async function log_event (events_drive, type, data) {
    if (!events_drive) {
      console.warn(`[log_event] Cannot log ${type} event: events_drive not provided`)
      return
    }
    
    try {
      const event = {
        type,
        data,
        meta: {
          time: Date.now()
        }
      }
      
      const event_path = `/events/${event.meta.time}-${type}.json`
      await events_drive.put(event_path, b4a.from(JSON.stringify(event)))
      console.log(`[log_event] Logged ${type} event`)
    } catch (err) {
      console.error('Error logging event:', err)
    }
  }

  // Get all events from events drive
  async function get_events (events_drive) {
    if (!events_drive) return []
    
    try {
      await events_drive.ready()
      const events = []
      const files = await events_drive.list('/events')
      
      for (const file of files) {
        try {
          const content = await events_drive.get(file)
          if (content) {
            events.push(JSON.parse(b4a.toString(content)))
          }
        } catch (err) {
          console.error('Error reading event file:', file, err)
        }
      }
      
      return events.sort((a, b) => a.meta.time - b.meta.time)
    } catch (err) {
      console.error('Error getting events:', err)
      return []
    }
  }

  // Get paired devices from events 
  async function get_paired_devices (events_drive_param) {
    const events = await get_events(events_drive_param)
    const devices_map = new Map()
    let device_counter = 0 // Start at 0 so bootstrap device is Device 1
    
    // Process events in order to track add/remove
    for (const event of events) {
      if (event.type === 'add') {
        const device_id = event.data.metadata_writer
        device_counter++
        const device_name = `Device ${device_counter}`
        
        // Build device object dynamically with ALL writer keys from event data
        const device = {
          name: device_name,
          timestamp: event.meta.time,
          added_date: new Date(event.meta.time).toLocaleString()
        }
        
        // Copy all writer keys from event data
        for (const [key, value] of Object.entries(event.data)) {
          if (key.endsWith('_writer')) {
            device[key] = value
          }
        }
        
        devices_map.set(device_id, device)
      } else if (event.type === 'remove') {
        const device_id = event.data.metadata_writer
        devices_map.delete(device_id)
      }
    }
    
    return Array.from(devices_map.values())
  }

  // Get device name by metadata writer key
  async function get_device_name (events_drive_param, metadata_writer_key) {
    const devices = await get_paired_devices(events_drive_param)
    const device = devices.find(d => d.metadata_writer === metadata_writer_key)
    return device ? device.name : null
  }

  // Remove device by removing writer access from all structures (dynamic)
  async function remove_device (events_drive_param, device) {
    if (!ds_manager) {
      console.error('Datastructure manager not initialized')
      return false
    }
    
    try {
      // Dynamically remove writers from ALL structures
      const structure_names = ds_manager.get_names()
      const removal_data = {}
      
      for (const name of structure_names) {
        const writer_key_name = `${name}_writer`
        const writer_key = device[writer_key_name]
        
        if (writer_key) {
          removal_data[writer_key_name] = writer_key
          
          try {
            await ds_manager.remove_writer(name, writer_key)
            console.log(`Removed writer from ${name}`)
          } catch (err) {
            console.warn(`Failed to remove writer from ${name}:`, err.message)
          }
        }
      }
      
      // Log the removal event with all writer keys
      await log_event(events_drive_param, 'remove', removal_data)
      
      console.log('Device removed successfully')
      emitter.emit('update')
      return true
    } catch (err) {
      console.error('Error removing device:', err)
      return false
    }
  }

  // Get raw data from any structure (dynamic with ds_manager)
  async function get_raw_data (structure_name) {
    if (!ds_manager) return 'Datastructure manager not initialized'
    
    const structure = ds_manager.get(structure_name)
    if (!structure) return `Structure '${structure_name}' not found`
    
    const config = ds_manager.get_config(structure_name)
    
    try {
      if (config.type === 'autobase') {
        // For autobase: show all entries
        await structure.ready()
        if (structure.view.length === 0) return `Autobase '${structure_name}' is empty`
        
        const entries = []
        for (let i = 0; i < structure.view.length; i++) {
          try {
            const raw = await structure.view.get(i)
            const parsed = JSON.parse(raw)
            entries.push(`[${i}] ${JSON.stringify(parsed, null, 2)}`)
          } catch (err) {
            entries.push(`[${i}] Error: ${err.message}`)
          }
        }
        return entries.join('\n\n')
        
      } else if (config.type === 'autodrive') {
        // For autodrive: list all files
        await structure.ready()
        const files = []
        
        try {
          const list = await structure.list('/')
          if (list.length === 0) return `Autodrive '${structure_name}' is empty`
          
          for (const file of list) {
            try {
              const content = await structure.get(file)
              files.push(`${file}:\n${content ? b4a.toString(content) : 'null'}`)
            } catch (err) {
              files.push(`${file}: Error: ${err.message}`)
            }
          }
        } catch (err) {
          return `List error: ${err.message}`
        }
        
        return files.join('\n\n---\n\n')
      }
      
      return `Unknown structure type: ${config.type}`
    } catch (err) {
      return `Error reading ${structure_name}: ${err.message}`
    }
  }

  // Set events drive (for device events only)
  const set_events_drive = (drive, store_instance, setup_callback) => {
    events_drive = drive
    events_store = store_instance
    
    // Setup event sync listeners if callback provided
    if (setup_callback) {
      setup_callback()
    }
    
    emitter.emit('update')
  }

  // Set datastructure manager for dynamic raw data access
  const set_ds_manager = (manager) => {
    ds_manager = manager
  }

  // Set pairing manager
  const set_pairing_manager = (manager) => {
    pairing_manager = manager
  }

  // Set swarm
  const set_swarm = (swarm_instance) => {
    swarm = swarm_instance
  }
  
  const set_dht = (dht_instance) => {
    dht = dht_instance
  }
  
  const set_keypair = (keypair_instance) => {
    keypair = keypair_instance
  }

  function handle_update_callback (cb) {
    return emitter.on('update', cb)
  }

  // Return vault object with all identity functions (app-independent only)
  return {
    // Config for apps to access
    config: vault_config,
    
    // Networking setup
    start_networking,
    
    // Events and device management (apps provide events_drive parameter)
    log_event,
    get_events,
    get_paired_devices,
    get_device_name,
    remove_device,
    
    // Debugging
    get_raw_data,
    
    // Setters 
    set_events_drive,
    set_ds_manager,
    set_pairing_manager,
    set_swarm,
    set_dht,
    set_keypair,
    
    // Getters
    get_events_drive: () => events_drive,
    get_events_store: () => events_store,
    get_store: () => store,
    get_swarm: () => swarm,
    get_dht: () => dht,
    get_keypair: () => keypair,
    
    // Events
    on_update: handle_update_callback
  }
}
